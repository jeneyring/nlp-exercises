{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824d76aa",
   "metadata": {},
   "source": [
    "### Prepare & Parsing text/data:\n",
    "After acquiring the data with NLP/web scraping methods, we need to parse the data into small bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70b0e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeneyring/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeneyring/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jeneyring/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to import nltk (natural language tool kit) to help with parsing:\n",
    "import nltk; nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bf271",
   "metadata": {},
   "source": [
    "Steps to parsing data:\n",
    "<br>\n",
    "    1) Convert text to all lower case for normalcy.<br>\n",
    "    2) Remove any accented characters, non-ASCII characters.<br>\n",
    "    3) Remove special characters.<br>\n",
    "    4) Stem or lemmatize the words.(stem = \"if b, then c\")<br>\n",
    "    5) Remove stopwords.(if, and, the, etc)<br>\n",
    "    6) Store the clean text and the original text for use in future notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05acc43",
   "metadata": {},
   "source": [
    "#NOTE: if your corpus is large enough, its ok to really clean up/strip down your text to become natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9056b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a38d364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa096cc",
   "metadata": {},
   "source": [
    "### Exercise 1)\n",
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "Lowercase everything\n",
    "Normalize unicode characters\n",
    "Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c6067b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You all call me fugitive, which court has ever...</td>\n",
       "      <td>Lalit Modi on Sunday took to Instagram to spea...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World's biggest NFT marketplace OpenSea fires ...</td>\n",
       "      <td>The world's first and biggest NFT marketplace ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>16 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCCI had ₹40 cr in bank when I joined &amp; ₹47,68...</td>\n",
       "      <td>In an Instagram post, Lalit Modi asserted that...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A fighter to the core: Mahindra praises PV Sin...</td>\n",
       "      <td>Businessman Anand Mahindra took to Twitter to ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter's sudden speed for trial after 2 month...</td>\n",
       "      <td>Tesla CEO Elon Musk has opposed Twitter's requ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>16 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  You all call me fugitive, which court has ever...   \n",
       "1  World's biggest NFT marketplace OpenSea fires ...   \n",
       "2  BCCI had ₹40 cr in bank when I joined & ₹47,68...   \n",
       "3  A fighter to the core: Mahindra praises PV Sin...   \n",
       "4  Twitter's sudden speed for trial after 2 month...   \n",
       "\n",
       "                                             content          author    date  \\\n",
       "0  Lalit Modi on Sunday took to Instagram to spea...  Ridham Gambhir  17 Jul   \n",
       "1  The world's first and biggest NFT marketplace ...  Ridham Gambhir  16 Jul   \n",
       "2  In an Instagram post, Lalit Modi asserted that...  Ridham Gambhir  17 Jul   \n",
       "3  Businessman Anand Mahindra took to Twitter to ...  Ridham Gambhir  17 Jul   \n",
       "4  Tesla CEO Elon Musk has opposed Twitter's requ...  Ridham Gambhir  16 Jul   \n",
       "\n",
       "   source  category  \n",
       "0     NaN  business  \n",
       "1     NaN  business  \n",
       "2     NaN  business  \n",
       "3     NaN  business  \n",
       "4     NaN  business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the df to consider what does need to be applied: \n",
    "#ie. I want to keep my titles upper case but my content can be lowercase\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a18b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lalit Modi on Sunday took to Instagram to speak about various issues after he revealed his relationship with Sushmita Sen. He wrote, \"[Though you all] call me a \"fugitive\"...tell me which court has ever convicted me...None…Everyone knows how difficult it is to do business in India.\" Speaking about IPL, he said, “Everyone...knows that I did it all alone\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying lowercase to one string in dataframe:\n",
    "string = original.content[0]\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a2cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowering all capitalized letters:\n",
    "string = string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1697f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the content of string:\n",
    "string=unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61bcd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing anything not a letter, number, whitespace or single quote:\n",
    "string = re.sub(r\"[^a-z0-9'\\s]\", '' ,string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbe6c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lalit modi on sunday took to instagram to speak about various issues after he revealed his relationship with sushmita sen he wrote though you all call me a fugitivetell me which court has ever convicted menoneeveryone knows how difficult it is to do business in india speaking about ipl he said everyoneknows that i did it all alone'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking output:\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b7cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting altogether in a function:\n",
    "\n",
    "def basic_clean(string):\n",
    "    \"\"\"A function that uses NLTK to clean and normalizes a string\"\"\"\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '' ,string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ce6a0",
   "metadata": {},
   "source": [
    "Another way to do this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b6da4",
   "metadata": {},
   "source": [
    "### Exercise 2)\n",
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3f2096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lalit modi on sunday took to instagram to speak about various issues after he revealed his relationship with sushmita sen he wrote though you all call me a fugitivetell me which court has ever convicted menoneeveryone knows how difficult it is to do business in india speaking about ipl he said everyoneknows that i did it all alone\n"
     ]
    }
   ],
   "source": [
    "#using toktoktokenizer to breakdown words into units:\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(string, return_str=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c66617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    \"\"\"This function will take in a string, tokenize by breaking any leftover words into units and return \n",
    "    the tokenized string\"\"\"\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33dcc419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The world\\'s first and biggest NFT marketplace OpenSea has fired 20% of its employees citing \"cryptocurrency winter\" and \"broad macroeconomic instability\". CEO Devin Finzer shared the news on Twitter and said the affected employees will be provided with a generous severance and healthcare coverage into 2023. He added that the company will also help in the placement of these employees. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing out functions:\n",
    "original2 = acquire.get_news_articles()\n",
    "string2 = original2.content[1]\n",
    "string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a2d87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the world's first and biggest nft marketplace opensea has fired 20 of its employees citing cryptocurrency winter and broad macroeconomic instability ceo devin finzer shared the news on twitter and said the affected employees will be provided with a generous severance and healthcare coverage into 2023 he added that the company will also help in the placement of these employees \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing all functions:\n",
    "cleaned = basic_clean(string2)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98643ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the world ' s first and biggest nft marketplace opensea has fired 20 of its employees citing cryptocurrency winter and broad macroeconomic instability ceo devin finzer shared the news on twitter and said the affected employees will be provided with a generous severance and healthcare coverage into 2023 he added that the company will also help in the placement of these employees\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing all functions:\n",
    "tokenize(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f34ae",
   "metadata": {},
   "source": [
    "### Exercise 3)\n",
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec466382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the stem tools: stem focuses on pull the root word out of any words with affixes (pre/suffix)\n",
    "# Create the nltk stemmer object, then use it-\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('call'), ps.stem('calling'), ps.stem('called')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a8ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world' first and biggest nft marketplac opensea ha fire 20 of it employe cite cryptocurr winter and broad macroeconom instabl ceo devin finzer share the news on twitter and said the affect employe will be provid with a gener sever and healthcar coverag into 2023 he ad that the compani will also help in the placement of these employe\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in cleaned.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ad1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    \"\"\"This function takes in a string and returns the stemmed version of string\"\"\"\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in cleaned.split()]\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef7373",
   "metadata": {},
   "source": [
    "### Exercise 4)\n",
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45bf22fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: he -- lemma: He\n",
      "stem: wa -- lemma: wa\n",
      "stem: run -- lemma: running\n",
      "stem: and -- lemma: and\n",
      "stem: eat -- lemma: eating\n",
      "stem: at -- lemma: at\n",
      "stem: same -- lemma: same\n",
      "stem: time. -- lemma: time.\n",
      "stem: he -- lemma: He\n",
      "stem: ha -- lemma: ha\n",
      "stem: bad -- lemma: bad\n",
      "stem: habit -- lemma: habit\n",
      "stem: of -- lemma: of\n",
      "stem: swim -- lemma: swimming\n",
      "stem: after -- lemma: after\n",
      "stem: play -- lemma: playing\n",
      "stem: long -- lemma: long\n",
      "stem: hour -- lemma: hour\n",
      "stem: in -- lemma: in\n",
      "stem: the -- lemma: the\n",
      "stem: sun. -- lemma: Sun.\n"
     ]
    }
   ],
   "source": [
    "#testing out lemmatizer:\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "\n",
    "for word in sentence.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f5322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: the -- lemma: the\n",
      "stem: world' -- lemma: world's\n",
      "stem: first -- lemma: first\n",
      "stem: and -- lemma: and\n",
      "stem: biggest -- lemma: biggest\n",
      "stem: nft -- lemma: nft\n",
      "stem: marketplac -- lemma: marketplace\n",
      "stem: opensea -- lemma: opensea\n",
      "stem: ha -- lemma: ha\n",
      "stem: fire -- lemma: fired\n",
      "stem: 20 -- lemma: 20\n",
      "stem: of -- lemma: of\n",
      "stem: it -- lemma: it\n",
      "stem: employe -- lemma: employee\n",
      "stem: cite -- lemma: citing\n",
      "stem: cryptocurr -- lemma: cryptocurrency\n",
      "stem: winter -- lemma: winter\n",
      "stem: and -- lemma: and\n",
      "stem: broad -- lemma: broad\n",
      "stem: macroeconom -- lemma: macroeconomic\n",
      "stem: instabl -- lemma: instability\n",
      "stem: ceo -- lemma: ceo\n",
      "stem: devin -- lemma: devin\n",
      "stem: finzer -- lemma: finzer\n",
      "stem: share -- lemma: shared\n",
      "stem: the -- lemma: the\n",
      "stem: news -- lemma: news\n",
      "stem: on -- lemma: on\n",
      "stem: twitter -- lemma: twitter\n",
      "stem: and -- lemma: and\n",
      "stem: said -- lemma: said\n",
      "stem: the -- lemma: the\n",
      "stem: affect -- lemma: affected\n",
      "stem: employe -- lemma: employee\n",
      "stem: will -- lemma: will\n",
      "stem: be -- lemma: be\n",
      "stem: provid -- lemma: provided\n",
      "stem: with -- lemma: with\n",
      "stem: a -- lemma: a\n",
      "stem: gener -- lemma: generous\n",
      "stem: sever -- lemma: severance\n",
      "stem: and -- lemma: and\n",
      "stem: healthcar -- lemma: healthcare\n",
      "stem: coverag -- lemma: coverage\n",
      "stem: into -- lemma: into\n",
      "stem: 2023 -- lemma: 2023\n",
      "stem: he -- lemma: he\n",
      "stem: ad -- lemma: added\n",
      "stem: that -- lemma: that\n",
      "stem: the -- lemma: the\n",
      "stem: compani -- lemma: company\n",
      "stem: will -- lemma: will\n",
      "stem: also -- lemma: also\n",
      "stem: help -- lemma: help\n",
      "stem: in -- lemma: in\n",
      "stem: the -- lemma: the\n",
      "stem: placement -- lemma: placement\n",
      "stem: of -- lemma: of\n",
      "stem: these -- lemma: these\n",
      "stem: employe -- lemma: employee\n"
     ]
    }
   ],
   "source": [
    "#using on cleaned data/shows stem vs lemmatized versions:\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "for word in cleaned.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d09b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"This function takes in a string and returns a lemmatized version of the string.\"\"\"\n",
    "    # create our lemmatizer object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use a list comprehension to lemmatize each word\n",
    "    # string.split() => output a list of every token inside of the document\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # glue the lemmas back together by the strings we split on\n",
    "    string = ' '.join(lemmas)\n",
    "    #return the altered document\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def6629",
   "metadata": {},
   "source": [
    "### Exercise 5)\n",
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e7a22",
   "metadata": {},
   "source": [
    " <b>note about sets vs list: putting a list of a dictionary together. It's items cannot be replaced.</b>\n",
    "- sets have similarities to a dictionary.\n",
    "- we can use sets in stopwords so that we make sure only unique words going into list (vs. not checking what words are already in stopwords...which could return duplicates if not careful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e392515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Example of list:\n",
    "list1 = [1,2,3,4]\n",
    "list2 = [2,1,3,4]\n",
    "\n",
    "print(set(list1)== set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c9d420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c'] {'c', 'a', 'b'}\n"
     ]
    }
   ],
   "source": [
    "#list vs set:\n",
    "mylist = ['a','b','c']\n",
    "\n",
    "myset = set(mylist)\n",
    "\n",
    "print(mylist, myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe582be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    \"\"\"This function takes in a string, applies stop_words to take out common stop words, includes any extra words\n",
    "    wanted removed and excludes and stop words wanted kept\"\"\"\n",
    "    #assign stopwords from nltk into a stopword_list:\n",
    "    stopword_list = stopwords.words('english')\n",
    "    #remove any excluded stopwords that are wanted to be kept:\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    #add on any other stopwords using a union\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    #split the words by spaces\n",
    "    words = string.split()\n",
    "    #filter out every word in dict unless in stop word:\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    #put it back together with spaces\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    #return df back\n",
    "    return string_without_stopwords\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca17c2f",
   "metadata": {},
   "source": [
    "### Exercise 6) \n",
    "Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab505bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You all call me fugitive, which court has ever...</td>\n",
       "      <td>Lalit Modi on Sunday took to Instagram to spea...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World's biggest NFT marketplace OpenSea fires ...</td>\n",
       "      <td>The world's first and biggest NFT marketplace ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>16 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCCI had ₹40 cr in bank when I joined &amp; ₹47,68...</td>\n",
       "      <td>In an Instagram post, Lalit Modi asserted that...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A fighter to the core: Mahindra praises PV Sin...</td>\n",
       "      <td>Businessman Anand Mahindra took to Twitter to ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter's sudden speed for trial after 2 month...</td>\n",
       "      <td>Tesla CEO Elon Musk has opposed Twitter's requ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>16 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Akshay &amp; Suniel's 'Mohra' was a risky film wit...</td>\n",
       "      <td>Filmmaker Rajiv Rai said his 1994 film 'Mohra'...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>It's true 'Rocky...' is delayed, still have so...</td>\n",
       "      <td>Karan Johar has confirmed the reports that 'Ro...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Man starts thinking of having kids when he's n...</td>\n",
       "      <td>Actor Ranbir Kapoor, speaking about the though...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I was mistaken for Anil after 'JugJugg Jeeyo' ...</td>\n",
       "      <td>Actor Sanjay Kapoor revealed he was mistaken f...</td>\n",
       "      <td>Kriti Kambiri</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Shamshera made for masses, this was something ...</td>\n",
       "      <td>Actor Sanjay Dutt has said that his upcoming f...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>17 Jul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   You all call me fugitive, which court has ever...   \n",
       "1   World's biggest NFT marketplace OpenSea fires ...   \n",
       "2   BCCI had ₹40 cr in bank when I joined & ₹47,68...   \n",
       "3   A fighter to the core: Mahindra praises PV Sin...   \n",
       "4   Twitter's sudden speed for trial after 2 month...   \n",
       "..                                                ...   \n",
       "95  Akshay & Suniel's 'Mohra' was a risky film wit...   \n",
       "96  It's true 'Rocky...' is delayed, still have so...   \n",
       "97  Man starts thinking of having kids when he's n...   \n",
       "98  I was mistaken for Anil after 'JugJugg Jeeyo' ...   \n",
       "99  Shamshera made for masses, this was something ...   \n",
       "\n",
       "                                              content          author    date  \\\n",
       "0   Lalit Modi on Sunday took to Instagram to spea...  Ridham Gambhir  17 Jul   \n",
       "1   The world's first and biggest NFT marketplace ...  Ridham Gambhir  16 Jul   \n",
       "2   In an Instagram post, Lalit Modi asserted that...  Ridham Gambhir  17 Jul   \n",
       "3   Businessman Anand Mahindra took to Twitter to ...  Ridham Gambhir  17 Jul   \n",
       "4   Tesla CEO Elon Musk has opposed Twitter's requ...  Ridham Gambhir  16 Jul   \n",
       "..                                                ...             ...     ...   \n",
       "95  Filmmaker Rajiv Rai said his 1994 film 'Mohra'...  Amartya Sharma  17 Jul   \n",
       "96  Karan Johar has confirmed the reports that 'Ro...  Amartya Sharma  17 Jul   \n",
       "97  Actor Ranbir Kapoor, speaking about the though...  Amartya Sharma  17 Jul   \n",
       "98  Actor Sanjay Kapoor revealed he was mistaken f...   Kriti Kambiri  17 Jul   \n",
       "99  Actor Sanjay Dutt has said that his upcoming f...  Amartya Sharma  17 Jul   \n",
       "\n",
       "    source       category  \n",
       "0      NaN       business  \n",
       "1      NaN       business  \n",
       "2      NaN       business  \n",
       "3      NaN       business  \n",
       "4      NaN       business  \n",
       "..     ...            ...  \n",
       "95     NaN  entertainment  \n",
       "96     NaN  entertainment  \n",
       "97     NaN  entertainment  \n",
       "98     NaN  entertainment  \n",
       "99     NaN  entertainment  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = acquire.get_news_articles()\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616d708",
   "metadata": {},
   "source": [
    "### Exercise 7)\n",
    "Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bc5761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = pd.Series(acquire.get_blog_articles('https://codeup.com/featured/what-jobs-can-you-get-after-a-coding-bootcamp-part-2-cloud-administration/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "830da405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    What Jobs Can You Get After a Coding Bootcamp?...\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3da257",
   "metadata": {},
   "source": [
    "### Exercise 8)\n",
    "For each dataframe, produce the following columns:\n",
    "\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86824f",
   "metadata": {},
   "source": [
    "#### Things I know I need to do :\n",
    "- cleaned version: normalize/tokenize, remove_stopwords\n",
    "- stemmed version: apply only stemmed function onto clean data\n",
    "- lemmatized vers: apply only lemma function to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thought process of applying to full df:\n",
    "# df['some_column'] = df['old_column'].apply(somefunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming content columns to original to show what og text was\n",
    "news_df.rename(columns={'content': 'original'}, inplace=True)\n",
    "codeup_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating function of above needed items:\n",
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a df and the string name for a text column with the\n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords,\n",
    "                                  extra_words=extra_words,\n",
    "                                  exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df['clean'].apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df['clean'].apply(lemmatize)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f19a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing function on news_df:\n",
    "prep_article_data(news_df, 'original', extra_words = ['ha'], exclude_words = ['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b512e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing function on codeup_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_article_data(codeup_df, 'original', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec13a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
